{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-23T13:41:42.927701Z",
     "start_time": "2024-07-23T13:41:42.911378Z"
    }
   },
   "source": [
    "#라이브러리 임포트\n",
    "import torch\n",
    "import torch.nn as nn   # 신경망 모듈\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ],
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:41:43.116516Z",
     "start_time": "2024-07-23T13:41:42.955834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "dataset_file_origin = 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
    "\n",
    "# 요청을 보내고 응답을 받기\n",
    "response = requests.get(dataset_file_origin)\n",
    "\n",
    "# 응답이 성공적이면 파일로 저장\n",
    "if response.status_code == 200:\n",
    "    # with 문 : 파일을 열고 작업을 완료한 후에 자동으로 파일을 닫아준다\n",
    "    with open('shakespeare.txt', 'w', encoding=\"utf-8\") as file:\n",
    "        file.write(response.text)\n",
    "        \n",
    "    print(\"파일이 성공적으로 다운로드되었습니다.\")\n",
    "    \n",
    "else:\n",
    "    print(f\"파일 다운로드 실패: 상태 코드 {response.status_code}\")\n",
    "        "
   ],
   "id": "d2a2d592c93fc8f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일이 성공적으로 다운로드되었습니다.\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:41:43.155954Z",
     "start_time": "2024-07-23T13:41:43.123075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text=\"\"\n",
    "with open(\"shakespeare.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "print(text[:100])"
   ],
   "id": "38787ba7a6bbe10a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:41:43.233358Z",
     "start_time": "2024-07-23T13:41:43.193239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "# 문자 단위로 잘라서 리스트로 생성\n",
    "'''\n",
    "문자열을 단어 단위가 아니라 문자 단위로 전처리하는 이유?\n",
    "\n",
    "- 단어 단위보다 문자 단위로 작업하면 모델이 보다 세밀한 텍스트를 생성할 수 있다\n",
    "- 모델 복잡도를 줄여준다. 특정 언어에 종속되지 않는다.\n",
    "    근데 여기서 의문점... 한국어는 어떻게 처리할까?\n",
    "     => 한 글자 단위로 분해하게 되는데, 자음과 모음의 조합으로 음절을 형성함으로, 조합 가능한 개수가 더 많다. (영어는 알파벳, 숫자, 구두점 등을 모두 포함해도 100미만의 문자로 충분)\n",
    "     => 따라서, 한국어를 문자 단위로 처리할 떄는 더 많은 유니크한 문자를 처리해야 하는데, 이러한 접근 방식은 한국의 음절 구조와 자모 결합 패턴을 학습할 수 있다는 것이다.\n",
    "'''\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(chars)}"
   ],
   "id": "6320581236093a68",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:41:43.327163Z",
     "start_time": "2024-07-23T13:41:43.302622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 시퀀스 데이터 생성 함수 정의\n",
    "'''\n",
    "텍스트 데이터를 일정 길이의 시퀀스로 분할하고, 시퀀스 다음에 오는 문자를 타겟으로 설정하여\n",
    "시퀀스-타켓 쌍을 생성하는 함수\n",
    "'''\n",
    "def creat_sequences(text, seq_length):\n",
    " sequences = []\n",
    " targets = []\n",
    " for i in range(0, len(text) - seq_length):\n",
    "     # 시퀀스 생성\n",
    "     seq = text[i:i+seq_length]\n",
    "     # 시퀀스 다음에 오는 문자\n",
    "     target = text[i+seq_length]\n",
    "     sequences.append([char_to_idx[char] for char in seq])\n",
    "     targets.append(char_to_idx[target])\n",
    " return sequences, targets\n",
    "         "
   ],
   "id": "69dfcb7a629de389",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:42:04.633725Z",
     "start_time": "2024-07-23T13:41:43.366260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 시퀀스 길이 설정\n",
    "seq_length = 100\n",
    "\n",
    "# 시퀀스 데이터 생성\n",
    "sequences, targets = creat_sequences(text, seq_length)"
   ],
   "id": "9ac915ed9887fe10",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:42:04.648727Z",
     "start_time": "2024-07-23T13:42:04.639244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 문자를 고유한 정수 인덱스로 매핑한 값들 출력\n",
    "print(sequences[:10])"
   ],
   "id": "375df6d26250bde7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59], [47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1], [56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39], [57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56], [58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43], [1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43, 1], [15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43, 1, 39], [47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43, 1, 39, 50], [58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43, 1, 39, 50, 50], [47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43, 1, 39, 50, 50, 1]]\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:42:04.663523Z",
     "start_time": "2024-07-23T13:42:04.650316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pytorch 데이터셋 및 데이터로더 생성\n",
    "\n",
    "# Pytorch의 Dataset 상속 받은 TextDataset 클래스 정의\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sequences[idx], dtype=torch.long), torch.tensor(self.targets[idx], dtype=torch.long)"
   ],
   "id": "7f65baf9aba01414",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:42:04.679227Z",
     "start_time": "2024-07-23T13:42:04.663523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 데이터셋 및 데이터로더 인스턴스 생성\n",
    "dataset = TextDataset(sequences, targets)\n",
    "\n",
    "# 데이터로더 : 데이터셋을 배치 단위로 묶어서 전달해주는 역할\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "'''\n",
    "<batch_size = 64>\n",
    "- 매번 64개의 시퀀스-타켓 쌍을 한 배치로 묶어서 모델에 제공\n",
    "- 예를 들어, 데이터셋에 1000개의 시퀀스가 있으면, 데이터로더는 1000/64 = 16개의 배치를 생성해 16번 배치를 모델에 전달함\n",
    "\n",
    "<shuffle = True>\n",
    "- 데이터를 섞어서 모델이 학습할 때 순서를 학습하는 것을 방지\n",
    "'''"
   ],
   "id": "57fdc6f0a25a45f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<batch_size = 64>\\n- 매번 64개의 시퀀스-타켓 쌍을 한 배치로 묶어서 모델에 제공\\n- 예를 들어, 데이터셋에 1000개의 시퀀스가 있으면, 데이터로더는 1000/64 = 16개의 배치를 생성해 16번 배치를 모델에 전달함\\n\\n<shuffle = True>\\n- 데이터를 섞어서 모델이 학습할 때 순서를 학습하는 것을 방지\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:42:04.689679Z",
     "start_time": "2024-07-23T13:42:04.682979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(chars)\n",
    "hidden_size = 256\n",
    "output_size = len(chars)\n",
    "num_layers = 2"
   ],
   "id": "4d75ad3e78ce6aba",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:42:04.704875Z",
     "start_time": "2024-07-23T13:42:04.692431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "'''\n",
    "device 변수\n",
    ": PyTorch에서 모델과 데이터를 GPU 또는 CPU에 올리기 위해 사용\n",
    "=> GPU가 사용 가능하면, cuda로 설정하고, 그렇지 않으면 cpu로 설정\n",
    "'''"
   ],
   "id": "7b85e9ef69a0d057",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndevice 변수\\n: PyTorch에서 모델과 데이터를 GPU 또는 CPU에 올리기 위해 사용\\n=> GPU가 사용 가능하면, cuda로 설정하고, 그렇지 않으면 cpu로 설정\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:42:04.716364Z",
     "start_time": "2024-07-23T13:42:04.704875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RNN 모델을 사용한 클래스 정의\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(vocab_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)"
   ],
   "id": "963fcd38d1459e31",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:42:04.733578Z",
     "start_time": "2024-07-23T13:42:04.717879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 모델 인스턴스 생성 및 GPU로 이동\n",
    "model = RNNModel(vocab_size, hidden_size, output_size, num_layers).to(device)"
   ],
   "id": "a3fd303e3a5090f6",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:42:04.745969Z",
     "start_time": "2024-07-23T13:42:04.738092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 손실 함수와 최적화 함수 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "46de9b32cf65e6d1",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:42:04.760476Z",
     "start_time": "2024-07-23T13:42:04.748989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 모델 훈련 함수\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=200):\n",
    "    # 모델을 훈련 모드로 설정\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            # 원-핫 인코딩 및 GPU로 이동\n",
    "            inputs = nn.functional.one_hot(inputs, num_classes=vocab_size).float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 각 배치마다 hidden 상태 초기화\n",
    "            hidden = model.init_hidden(inputs.size(0))\n",
    "            \n",
    "            # 옵티마이저 초기화\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 순전파, 역전파, 최적화\n",
    "            outputs, hidden = model(inputs, hidden)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # hidden 상태를 detach()로 분리\n",
    "            hidden = hidden.detach()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(dataloader):.4f}\")\n",
    "    print('Finished Training')"
   ],
   "id": "cd2503a254dcccad",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:42:04.775799Z",
     "start_time": "2024-07-23T13:42:04.762320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 텍스트 생성 함수\n",
    "def gererate_text(model, start_str, length, temperature=1.0):\n",
    "    # 모델을 평가 모드로 설정\n",
    "    model.eval()\n",
    "    hidden = model.init_hidden(1)\n",
    "    \n",
    "    input_seq = torch.tensor([char_to_idx[char] for char in start_str]).unsqueeze(0).to(device)\n",
    "    generated_text = start_str\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(length):\n",
    "            input_seq = nn.functional.one_hot(input_seq, num_classes=vocab_size).float()\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "            \n",
    "            # 다음 문자를 샘플링\n",
    "            output = output.squeeze().div(temperature).exp().cpu()\n",
    "            top_char = torch.multinomial(output, 1)[0]\n",
    "            \n",
    "            generated_char = idx_to_char[top_char.item()]\n",
    "            generated_text += generated_char\n",
    "            \n",
    "            # 다음 입력 시퀀스 준비\n",
    "            input_seq = torch.tensor([[top_char]]).to(device)\n",
    "    \n",
    "    return generated_text"
   ],
   "id": "f59e20199e2e4ff4",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:42:04.787386Z",
     "start_time": "2024-07-23T13:42:04.777396Z"
    }
   },
   "cell_type": "code",
   "source": "print(model)",
   "id": "b6431db8aa43799f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (rnn): RNN(65, 256, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=65, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T14:01:03.472732Z",
     "start_time": "2024-07-23T13:42:04.787386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 모델 훈련\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs=5)"
   ],
   "id": "c77a8cc642073dc9",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[103], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 모델 훈련\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train_model(model, dataloader, criterion, optimizer, num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n",
      "Cell \u001B[1;32mIn[100], line 21\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, dataloader, criterion, optimizer, num_epochs)\u001B[0m\n\u001B[0;32m     19\u001B[0m outputs, hidden \u001B[38;5;241m=\u001B[39m model(inputs, hidden)\n\u001B[0;32m     20\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[1;32m---> 21\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     22\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     24\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    524\u001B[0m     )\n\u001B[1;32m--> 525\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[0;32m    526\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[0;32m    527\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 267\u001B[0m _engine_run_backward(\n\u001B[0;32m    268\u001B[0m     tensors,\n\u001B[0;32m    269\u001B[0m     grad_tensors_,\n\u001B[0;32m    270\u001B[0m     retain_graph,\n\u001B[0;32m    271\u001B[0m     create_graph,\n\u001B[0;32m    272\u001B[0m     inputs,\n\u001B[0;32m    273\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    274\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    275\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    745\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    746\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T14:01:03.472732Z",
     "start_time": "2024-07-23T14:01:03.472732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 테스트 시작 문자열 및 생서할 텍스트 길이 설정\n",
    "start_str = 'To be, or not to be, that is the question:'\n",
    "length = 200"
   ],
   "id": "75420a6c3f6abe93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 텍스트 생성\n",
    "generated_text = gererate_text(model, start_str, length, temperature=0.8)\n",
    "print(generated_text)"
   ],
   "id": "47b9c80e483ce934",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dce34a7b1099a044"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
